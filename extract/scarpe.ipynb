{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import  urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import markdownify as md\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.archanaskitchen.com/\"\n",
    "no_pages = 337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText(element):\n",
    "    if element:\n",
    "        return element.text.strip()\n",
    "    else:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoContentException(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_recipe_data(soup):\n",
    "    data = {}\n",
    "    header = soup.select_one(\".recipe-header\")\n",
    "    if not header:\n",
    "        raise NoContentException\n",
    "    data[\"title\"] = getText(header.select_one(\".recipe-title\"))\n",
    "    data[\"shortdescription\"] = getText(header.select_one(\"p\"))\n",
    "    data[\"author\"] = getText(soup.find(attrs={\"itemprop\":\"author\"}))\n",
    "    data[\"created\"] = soup.select_one(\".itemDateCreated\").attrs[\"content\"]\n",
    "    data[\"image\"] = urljoin(base_url,soup.select_one(\".recipe-image\").find(\"img\").attrs[\"src\"])\n",
    "\n",
    "    html = \" \".join([str(x) for x in soup.select_one(\".recipedescription\").contents]).strip()\n",
    "    data[\"description\"] = md.markdownify(html, heading_style=\"ATX\")\n",
    "\n",
    "    table = soup.select_one(\".cuisineandcourse\")\n",
    "    if table:\n",
    "        cusine = table.select_one(\".cuisine\")\n",
    "        if cusine:\n",
    "            data[\"cuisine\"] = cusine.find(attrs={\"itemprop\":\"recipeCuisine\"}).text.lower().replace(\"recipes\",\"\").strip()\n",
    "        course = table.select_one(\".course\")\n",
    "        if course:\n",
    "            data[\"course\"] = course.find(attrs={\"itemprop\":\"keywords\"}).text.strip().lower()\n",
    "        diet = table.select_one(\".diet\")\n",
    "        if diet:\n",
    "            data[\"diet\"] = diet.find(attrs={\"itemprop\":\"keywords\"}).text.strip().lower()\n",
    "        equipments = table.select_one(\".products\")\n",
    "        data[\"equipments\"] = None\n",
    "        if equipments:\n",
    "            data[\"equipments\"] = [x.text.strip().lower() for x in equipments.select(\"a\")]\n",
    "\n",
    "    table = soup.select_one(\".RecipeServesTime\")\n",
    "    if table:\n",
    "        data[\"prepTime\"] = re.findall(r'\\d+', table.find(attrs={\"itemprop\":\"prepTime\"}).text)[0]\n",
    "        data[\"cookTime\"] = re.findall(r'\\d+', table.find(attrs={\"itemprop\":\"cookTime\"}).text)[0]\n",
    "        data[\"totalTime\"] = re.findall(r'\\d+', table.find(attrs={\"itemprop\":\"totalTime\"}).text)[0]\n",
    "        serving = table.find(attrs={\"itemprop\":\"recipeYield\"})\n",
    "        data[\"servings\"] = None\n",
    "        if serving:\n",
    "            data[\"servings\"] = re.findall(r'\\d+', serving.text)[0]\n",
    "    ingredients = soup.select_one(\".recipeingredients\")\n",
    "    data[\"ingredients\"]=None\n",
    "    if ingredients:\n",
    "        data[\"ingredients\"] = [\" \".join(x.text.split()) for x in ingredients.find_all(\"li\",attrs={\"itemprop\":\"ingredients\"})]\n",
    "\n",
    "    html = \" \".join([str(x) for x in soup.select_one(\".recipeinstructions\").contents]).strip()\n",
    "    data[\"instructions\"] = md.markdownify(html, heading_style=\"ATX\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock = threading.Lock()\n",
    "\n",
    "soups = {}\n",
    "recipies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_error_url(url,e):\n",
    "    global error_urls\n",
    "    with lock:\n",
    "        error_urls.append((url,e))\n",
    "\n",
    "def store_soup(url,soup):\n",
    "    global soups\n",
    "    with lock:\n",
    "        soups[url] = soup\n",
    "\n",
    "def get_soup_from_cache(url):\n",
    "    global soups\n",
    "    with lock:\n",
    "        try:\n",
    "            return soups[url]\n",
    "        except KeyError:\n",
    "            return None\n",
    "\n",
    "def store_recipie(url,recipie):\n",
    "    global recipies\n",
    "    with lock:\n",
    "        recipies[url] = recipie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pages(start:int,end:int):\n",
    "    for i in range(start,end):\n",
    "        page_url = urljoin(base_url,f\"/recipes/page-{i}\")\n",
    "        response = requests.get(page_url)\n",
    "        s = BeautifulSoup(response.text)\n",
    "        for card in s.select_one(\"#ak_recipe_categoryblog\").select(\".blogRecipe\"):\n",
    "            url = urljoin(base_url,card.find(\"a\").attrs[\"href\"])\n",
    "            soup = get_soup_from_cache(url)\n",
    "            if soup is None:\n",
    "                response = requests.get(url)\n",
    "                soup = BeautifulSoup(response.text)\n",
    "                store_soup(url,soup)\n",
    "            print(f\"{i}: {url}\")\n",
    "            try:\n",
    "                recipie= extract_recipe_data(soup) \n",
    "                store_recipie(url,recipie)\n",
    "            except Exception as e:\n",
    "                append_error_url(url,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "max_threads = os.cpu_count()-1\n",
    "\n",
    "threads = []\n",
    "error_urls = []\n",
    "\n",
    "for i in range(no_pages//max_threads+1):\n",
    "    args = (i*max_threads+1,min((i+1)*max_threads,no_pages+1))\n",
    "    thread = threading.Thread(target=extract_pages, args=args)\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7525"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recipies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data.json\",\"w\") as fh:\n",
    "    json.dump(recipies,fh,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://www.archanaskitchen.com/carrot-capsicum-mushroom-sweet-corn-tawa-sabzi-recipe',\n",
       "  __main__.NoContentException()),\n",
       " ('https://www.archanaskitchen.com/open-toast-macaroni-recipe',\n",
       "  __main__.NoContentException())]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill\n",
    "\n",
    "# with open(\"soups.pik\",\"wb\") as fh:\n",
    "#     dill.dump(soups,fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"soups.pik\",\"rb\") as fh:\n",
    "#     soups = dill.load(fh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
